{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numba as nb\n",
    "from minepy import MINE\n",
    "from minepy import pstats, cstats\n",
    "\n",
    "string_limit = 850\n",
    "\n",
    "anno = pd.read_csv(\"./annotation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mic(x, y):\n",
    "    mine = MINE(alpha=0.6, c=15)\n",
    "    mine.compute_score(x, y)\n",
    "    return mine.mic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = anno[anno[\"time\"] != 'Baseline'][\"geo\"]\n",
    "ctrl = anno[anno[\"time\"] == 'Baseline'][\"geo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringdb = pd.read_csv(\"StringDB_link.csv\", delimiter=\" \")\n",
    "stringdb[\"protein1\"] = stringdb[\"protein1\"].str.slice(start=5)\n",
    "stringdb[\"protein2\"] = stringdb[\"protein2\"].str.slice(start=5)\n",
    "stringdb = stringdb[stringdb[\"combined_score\"] >= string_limit]\n",
    "stringdb = stringdb.reset_index(drop=True)\n",
    "\n",
    "dict1 = pd.read_csv(\"./id.csv\")\n",
    "length = len(np.unique(dict1[\"symbol\"].values))\n",
    "fpkm = pd.read_csv(\"./exprSet_fine.csv\")\n",
    "\n",
    "d = {dict1[\"ensp\"][i]: int(dict1[\"id\"][i]) for i in range(len(dict1))}\n",
    "d2 = {int(dict1[\"id\"][i]): dict1[\"symbol\"][i] for i in range(len(dict1))}\n",
    "string_bool = np.zeros([length, length])\n",
    "\n",
    "\n",
    "for i in range(len(stringdb)):\n",
    "    if (stringdb[\"protein1\"][i] in d) & (stringdb[\"protein2\"][i] in d):\n",
    "        string_bool[d[stringdb[\"protein1\"][i]], d[stringdb[\"protein2\"][i]]] = 1\n",
    "\n",
    "np.fill_diagonal(string_bool, 0)\n",
    "string_bool = string_bool == 1\n",
    "\n",
    "origin_frame = fpkm[ctrl].to_numpy()\n",
    "origin_sd = np.std(origin_frame, ddof=1, axis=1)\n",
    "\n",
    "num = len(origin_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a placeholder for the MIC values\n",
    "origin_mic = np.zeros(string_bool.shape)\n",
    "\n",
    "# Populate the MIC values only where string_bool is True\n",
    "for i in range(num):\n",
    "    for j in range(i - 1):\n",
    "        if string_bool[i, j]:\n",
    "            mic_value = calc_mic(origin_frame[i, :], origin_frame[j, :])\n",
    "            origin_mic[i, j] = mic_value\n",
    "            origin_mic[j, i] = mic_value  # MIC is symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "edge_origin_list = []\n",
    "\n",
    "idlist1 = []\n",
    "idlist2 = []\n",
    "for i in range(num):\n",
    "    for j in range(i - 1):\n",
    "        if string_bool[i, j] != 0:\n",
    "            edge_origin_list.append([d2[i], d2[j]])\n",
    "            idlist1.append(i)\n",
    "            idlist2.append(j)\n",
    "\n",
    "edge_origin_entropy = np.zeros((len(idlist1)), dtype=np.float64)\n",
    "edge_origin_sd = np.zeros((len(idlist1)), dtype=np.float64)\n",
    "idlist1 = nb.typed.List(idlist1)\n",
    "idlist2 = nb.typed.List(idlist2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy calculation\n",
    "@nb.njit(parallel=False)\n",
    "def entropy(pc, sd, idlist1, idlist2, edge_entropy, edge_sd):\n",
    "    for i in range(len(idlist1)):\n",
    "        p1 = idlist1[i]\n",
    "        p2 = idlist2[i]\n",
    "\n",
    "        left_not_zero = np.where(pc[p1] != 0)[0]\n",
    "        right_not_zero = np.where(pc[p2] != 0)[0]\n",
    "\n",
    "        left_not_zero = np.delete(left_not_zero, np.where(left_not_zero == p2)[0])\n",
    "        right_not_zero = np.delete(right_not_zero, np.where(right_not_zero == p1)[0])\n",
    "\n",
    "        len_left_not_zero = len(left_not_zero)\n",
    "        len_right_not_zero = len(right_not_zero)\n",
    "\n",
    "        if len_left_not_zero < 2 and len_right_not_zero < 2:\n",
    "            edge_entropy[i] = 0\n",
    "            edge_sd[i] = 0\n",
    "            continue\n",
    "        if len_left_not_zero < 2 and len_right_not_zero > 1:\n",
    "            right_prob = (pc[p2][right_not_zero]) / np.sum((pc[p2][right_not_zero]))\n",
    "            right_entropy = -np.sum(right_prob * np.log2(right_prob)) / np.log2(\n",
    "                len_right_not_zero\n",
    "            )\n",
    "            entropy = (\n",
    "                right_entropy\n",
    "                / (len_left_not_zero + len_right_not_zero)\n",
    "                * len_right_not_zero\n",
    "            )\n",
    "            edge_entropy[i] = entropy\n",
    "            edge_sd[i] = (sd[p1] * len_left_not_zero + sd[p2] * len_right_not_zero) / (\n",
    "                len_left_not_zero + len_right_not_zero\n",
    "            )\n",
    "            continue\n",
    "        if len_left_not_zero > 1 and len_right_not_zero < 2:\n",
    "            left_prob = (pc[p1][left_not_zero]) / np.sum((pc[p1][left_not_zero]))\n",
    "            left_entropy = -np.sum(left_prob * np.log2(left_prob)) / np.log2(\n",
    "                len_left_not_zero\n",
    "            )\n",
    "            entropy = (\n",
    "                left_entropy\n",
    "                / (len_left_not_zero + len_right_not_zero)\n",
    "                * len_left_not_zero\n",
    "            )\n",
    "            edge_entropy[i] = entropy\n",
    "            edge_sd[i] = (sd[p1] * len_left_not_zero + sd[p2] * len_right_not_zero) / (\n",
    "                len_left_not_zero + len_right_not_zero\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        edge_sd[i] = (sd[p1] * len_left_not_zero + sd[p2] * len_right_not_zero) / (\n",
    "            len_left_not_zero + len_right_not_zero\n",
    "        )\n",
    "        left_prob = (pc[p1][left_not_zero]) / np.sum((pc[p1][left_not_zero]))\n",
    "        right_prob = (pc[p2][right_not_zero]) / np.sum((pc[p2][right_not_zero]))\n",
    "        left_entropy = -np.sum(left_prob * np.log2(left_prob)) / np.log2(\n",
    "            len_left_not_zero\n",
    "        )\n",
    "        right_entropy = -np.sum(right_prob * np.log2(right_prob)) / np.log2(\n",
    "            len_right_not_zero\n",
    "        )\n",
    "        entropy = (\n",
    "            right_entropy * len_right_not_zero + left_entropy * len_left_not_zero\n",
    "        ) / (len_left_not_zero + len_right_not_zero)\n",
    "        edge_entropy[i] = entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy(origin_mic, origin_sd, idlist1, idlist2, edge_origin_entropy, edge_origin_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_frame2 = pd.read_csv(\"./exprSet_fine.csv\",index_col=0)\n",
    "append_len = np.shape(append_frame2)[1]\n",
    "id_len = len(idlist1)\n",
    "landscape2 = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in append_frame2.columns:\n",
    "    print(k, end=\"\\n\")\n",
    "\n",
    "    append_frame3 = np.column_stack((origin_frame, append_frame2[k]))\n",
    "\n",
    "    append_mic = np.zeros(string_bool.shape)\n",
    "\n",
    "    for i in range(num):\n",
    "        for j in range(i - 1):\n",
    "            if string_bool[i, j]:\n",
    "                mic_value = calc_mic(append_frame3[i, :], append_frame3[j, :])\n",
    "                append_mic[i, j] = mic_value\n",
    "                append_mic[j, i] = mic_value\n",
    "        \n",
    "    append_sd = np.std(append_frame3, ddof=1, axis=1)\n",
    "    edge_append_entropy = np.zeros((len(idlist1)), dtype=np.float64)\n",
    "    edge_append_sd = np.zeros((len(idlist1)), dtype=np.float64)\n",
    "\n",
    "    entropy(append_mic, append_sd, idlist1, idlist2, edge_append_entropy, edge_append_sd)\n",
    "\n",
    "    edge_append_entropy = np.abs(edge_append_entropy - edge_origin_entropy)\n",
    "    edge_append_sd = np.abs(edge_append_sd - edge_origin_sd)\n",
    "\n",
    "    landscape_pros = pd.DataFrame(edge_append_sd * edge_append_entropy)\n",
    "    landscape_pros.columns = [k]\n",
    "    landscape2 = pd.concat([landscape2, landscape_pros], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landscape2 = pd.concat([pd.DataFrame(edge_origin_list, columns=['node1', 'node2']), landscape2], axis=1)\n",
    "landscape2 = landscape2.fillna(0)\n",
    "landscape2.to_csv(\"edge_entropy_logM-1_\" + str(string_limit) + \"_mic.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55e31c4e4f96b3c43367ddd46a98c4f8ab367bfa08c9b39ce4151defbbfc00d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
